# Lexical Analyzer - DFA-Based Token Analysis

A modern, full-stack web application for lexical analysis using **Deterministic Finite Automata (DFA)**. Built with Next.js, React, TypeScript, and Tailwind CSS following software engineering best practices.

![Lexical Analyzer](https://img.shields.io/badge/TypeScript-007ACC?style=for-the-badge&logo=typescript&logoColor=white)
![Next.js](https://img.shields.io/badge/Next.js-000000?style=for-the-badge&logo=next.js&logoColor=white)
![React](https://img.shields.io/badge/React-20232A?style=for-the-badge&logo=react&logoColor=61DAFB)
![Tailwind CSS](https://img.shields.io/badge/Tailwind_CSS-38B2AC?style=for-the-badge&logo=tailwind-css&logoColor=white)

## ğŸŒ Live Demo

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2F1at23cs079-Mahi%2Ftocproject&project-name=lexical-analyzer-dfa&repository-name=tocproject)

## ğŸ¯ Overview

This lexical analyzer (lexer) breaks source code into **tokens** using a DFA-based approach. It provides:

- **Token Analysis**: Identifies keywords, identifiers, operators, literals, punctuation, and comments
- **Error Detection**: Catches invalid characters and malformed tokens with precise location tracking
- **Syntax Highlighting**: Color-codes tokens for better visualization
- **DFA Visualization**: Interactive state diagram showing the automaton structure
- **Real-time Analysis**: Immediate feedback with line and column tracking

## ğŸš€ Quick Start

### Prerequisites

- **Node.js** 18.x or higher
- **npm** or **yarn** package manager

### Installation

1. **Clone or navigate to the project directory**:
   ```bash
   cd toc
   ```

2. **Install dependencies**:
   ```bash
   npm install
   ```

3. **Run the development server**:
   ```bash
   npm run dev
   ```

4. **Open your browser** and navigate to:
   ```
   http://localhost:3000
   ```

### Build for Production

```bash
npm run build
npm start
```

## ğŸŒ Vercel Deployment

### One-Click Deploy

Click the button below to deploy directly to Vercel:

[![Deploy with Vercel](https://vercel.com/button)](https://vercel.com/new/clone?repository-url=https%3A%2F%2Fgithub.com%2F1at23cs079-Mahi%2Ftocproject&project-name=lexical-analyzer-dfa&repository-name=tocproject)

### Manual Deployment via Vercel CLI

1. **Install Vercel CLI**:
   ```bash
   npm install -g vercel
   ```

2. **Deploy from project directory**:
   ```bash
   vercel
   ```

3. **Follow the prompts** to configure your deployment

### GitHub Integration

Connect your GitHub repository to Vercel for automatic deployments:
1. Go to [Vercel Dashboard](https://vercel.com/dashboard)
2. Click "New Project"
3. Select your GitHub repository
4. Vercel will automatically detect Next.js configuration
5. Click "Deploy"

## ğŸ“‹ Available Scripts

| Command | Description |
|---------|-------------|
| `npm run dev` | Start development server |
| `npm run build` | Build for production |
| `npm start` | Run production server |
| `npm run lint` | Run ESLint |
| `npm test` | Run Jest tests |
| `npm run test:watch` | Run tests in watch mode |
| `npm run format` | Format code with Prettier |

## ğŸ—ï¸ Architecture

The application follows **Clean Architecture** principles with clear separation of concerns:

```
toc/
â”œâ”€â”€ app/                      # Next.js 14 App Router
â”‚   â”œâ”€â”€ page.tsx             # Main application page
â”‚   â”œâ”€â”€ layout.tsx           # Root layout with metadata
â”‚   â””â”€â”€ globals.css          # Global styles
â”œâ”€â”€ components/              # React components (Presentation Layer)
â”‚   â”œâ”€â”€ CodeEditor.tsx       # Code input with line numbers
â”‚   â”œâ”€â”€ TokenTable.tsx       # Token display with filtering/sorting
â”‚   â”œâ”€â”€ ErrorPanel.tsx       # Error messages display
â”‚   â”œâ”€â”€ DfaVisualizer.tsx    # DFA state diagram
â”‚   â””â”€â”€ SyntaxHighlighter.tsx # Token-based syntax highlighting
â”œâ”€â”€ core/                    # Business logic (Domain Layer)
â”‚   â”œâ”€â”€ types.ts            # TypeScript interfaces and enums
â”‚   â”œâ”€â”€ samples.ts          # Sample code snippets
â”‚   â””â”€â”€ lexer/
â”‚       â”œâ”€â”€ dfa.ts          # DFA implementation and lexical analyzer
â”‚       â””â”€â”€ visualization.ts # DFA visualization data generator
â”œâ”€â”€ __tests__/              # Unit tests
â”‚   â””â”€â”€ lexer.test.ts       # Comprehensive lexer tests
â””â”€â”€ [config files]          # TypeScript, ESLint, Tailwind, Jest configs
```

### Layer Responsibilities

- **Presentation Layer** (`components/`, `app/`): UI components and user interaction
- **Application Layer**: Use cases orchestrated in page components
- **Domain Layer** (`core/`): DFA logic, token definitions, lexical analysis
- **Infrastructure Layer**: Next.js framework, build configuration

## ğŸ¤– DFA Model Explanation

### States

The lexical analyzer uses a **Deterministic Finite Automaton** with the following states:

| State | Description | Accepting |
|-------|-------------|-----------|
| `START` | Initial state | No |
| `IN_IDENTIFIER` | Processing identifier/keyword | Yes |
| `IN_NUMBER` | Processing integer | Yes |
| `IN_FLOAT` | Processing floating-point number | Yes |
| `IN_STRING` | Processing string literal | Yes |
| `IN_OPERATOR` | Processing operator | Yes |
| `IN_COMMENT` | Processing comment | Yes |
| `WHITESPACE` | Processing whitespace | Yes |
| `PUNCTUATION` | Single-character punctuation | Yes |
| `ERROR` | Invalid character | No |

### Transition Logic

```
START state transitions:
  - letter [a-zA-Z_]           â†’ IN_IDENTIFIER
  - digit [0-9]                â†’ IN_NUMBER
  - quote [" or ']             â†’ IN_STRING
  - operator [+, -, *, /, etc.] â†’ IN_OPERATOR
  - "//"                       â†’ IN_COMMENT
  - whitespace                 â†’ WHITESPACE
  - punctuation [(, ), {, etc.] â†’ PUNCTUATION (immediate accept)
  - other                      â†’ ERROR

IN_IDENTIFIER:
  - letter/digit               â†’ IN_IDENTIFIER (self-loop)
  - other                      â†’ Accept, return to START

IN_NUMBER:
  - digit                      â†’ IN_NUMBER (self-loop)
  - '.' followed by digit      â†’ IN_FLOAT
  - other                      â†’ Accept, return to START

IN_FLOAT:
  - digit                      â†’ IN_FLOAT (self-loop)
  - other                      â†’ Accept, return to START

IN_STRING:
  - any character              â†’ IN_STRING (self-loop)
  - closing quote              â†’ Accept, return to START
  - EOF                        â†’ Error (unterminated string)

IN_OPERATOR:
  - Check multi-char operators â†’ IN_OPERATOR or Accept
  
IN_COMMENT:
  - any character              â†’ IN_COMMENT (self-loop)
  - newline                    â†’ Accept, return to START
```

### Token Recognition Rules

1. **Keywords**: Matched from predefined set (if, else, while, for, etc.)
2. **Identifiers**: Start with letter/underscore, followed by letters/digits/underscores
3. **Numbers**: Sequences of digits, optionally with decimal point and fractional part
4. **Strings**: Enclosed in " or ', supports escape sequences
5. **Operators**: Single-char (+, -, *, /) or multi-char (==, !=, <=, >=, &&, ||, ===, !==)
6. **Comments**: Start with //, continue to end of line
7. **Punctuation**: (, ), {, }, [, ], ;, ,, ., :, ?

## ğŸ¨ Features

### Core Features

- âœ… **DFA-Based Tokenization**: Pure finite automaton implementation
- âœ… **Comprehensive Token Types**: Keywords, identifiers, numbers, strings, operators, punctuation
- âœ… **Error Detection**: Invalid characters, unterminated strings with precise location
- âœ… **Line/Column Tracking**: Every token includes position information
- âœ… **Syntax Highlighting**: Real-time color-coded token display
- âœ… **DFA Visualization**: Interactive state diagram with ReactFlow

### UI/UX Features

- ğŸ¯ **Modern Interface**: Clean, responsive design with Tailwind CSS
- ğŸ” **Token Filtering**: Search and filter tokens by type or content
- ğŸ“Š **Sortable Table**: Click column headers to sort tokens
- ğŸ“ **Code Editor**: Line numbers, syntax highlighting overlay
- ğŸ¨ **Category Color Coding**: Visual distinction between token types
- ğŸ“± **Responsive Design**: Works on desktop, tablet, and mobile
- ğŸ›ï¸ **Sample Code**: Pre-built examples for quick testing

### Developer Features

- ğŸ§ª **Unit Tests**: Comprehensive Jest test suite
- ğŸ“ **TypeScript**: Full type safety throughout
- ğŸ¯ **SOLID Principles**: Clean, maintainable code structure
- ğŸ“– **Well-Documented**: Extensive comments and documentation
- ğŸ”§ **ESLint + Prettier**: Consistent code style
- âš¡ **Fast Development**: Hot reload with Next.js

## ğŸ§ª Testing

Run the test suite:

```bash
npm test
```

Test coverage includes:
- Keyword recognition
- Identifier validation
- Number parsing (integers and floats)
- String literal handling (with escape sequences)
- Operator recognition (single and multi-character)
- Comment processing
- Line and column tracking
- Error detection and recovery
- Complex code scenarios

## ğŸ› ï¸ Technology Stack

| Category | Technologies |
|----------|--------------|
| **Frontend Framework** | Next.js 14 (App Router) |
| **UI Library** | React 18 |
| **Language** | TypeScript 5 |
| **Styling** | Tailwind CSS 3 |
| **Visualization** | ReactFlow |
| **Icons** | Lucide React |
| **Testing** | Jest + React Testing Library |
| **Linting** | ESLint + Prettier |
| **Build Tool** | Next.js (Turbopack in dev) |

## ğŸ“š Supported Language Features

### Keywords (26)
```
if, else, while, for, return, function, var, let, const,
int, float, string, boolean, true, false, null, undefined,
class, this, new, void, break, continue, switch, case, default,
do, try, catch, finally, throw, import, export, from, as
```

### Operators (30+)
```
Arithmetic: +, -, *, /, %
Comparison: ==, !=, <, >, <=, >=, ===, !==
Logical: &&, ||, !
Bitwise: &, |, ^, ~, <<, >>
Assignment: =, +=, -=, *=, /=, %=
Increment/Decrement: ++, --
```

### Literals
- **Integers**: 0, 123, 999
- **Floats**: 3.14, 0.5, 123.456
- **Strings**: "hello", 'world', with escape sequences

### Punctuation
```
( ) { } [ ] ; , . : ?
```

### Comments
```javascript
// Single-line comments
```

## ğŸ“ Educational Value

This project demonstrates:

1. **Compiler Design**: First phase of compilation (lexical analysis)
2. **Automata Theory**: Practical DFA implementation
3. **Software Engineering**: Clean architecture, SOLID principles
4. **Modern Web Development**: React, TypeScript, Next.js best practices
5. **Testing**: Comprehensive unit test coverage
6. **UI/UX Design**: Responsive, accessible interface

## ğŸ¤ Contributing

To extend the lexer:

1. **Add new token types** in `core/types.ts`
2. **Extend DFA logic** in `core/lexer/dfa.ts`
3. **Update visualization** in `core/lexer/visualization.ts`
4. **Add tests** in `__tests__/lexer.test.ts`
5. **Update color schemes** in `components/TokenTable.tsx` and `SyntaxHighlighter.tsx`

## ğŸ“„ License

This project is created for educational purposes.

## ğŸ™ Acknowledgments

- Built following principles from "Compilers: Principles, Techniques, and Tools" (Dragon Book)
- DFA concepts based on formal language theory
- Modern web development practices from the React and Next.js communities

## ğŸ“ Support

For issues or questions:
1. Check the DFA documentation in `core/lexer/dfa.ts`
2. Review test cases in `__tests__/lexer.test.ts`
3. Examine sample code in `core/samples.ts`

---

**Built with â¤ï¸ using Clean Architecture and DFA Theory**
